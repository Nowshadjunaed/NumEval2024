{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad59f1",
   "metadata": {
    "id": "e5ad59f1",
    "outputId": "532bbe84-7ac5-4901-ac9c-87ea7212566d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 15:03:26.963358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, MT5ForConditionalGeneration, MT5Tokenizer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer\n",
    "os.environ['WANDB_SILENT']=\"true\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30221f36",
   "metadata": {
    "id": "30221f36"
   },
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "\n",
    "    input = batch['inputs'] #load original sentences\n",
    "    label = batch['ans_sent'] #load noisy sentences\n",
    "    inputs = tokenizer(input, text_target=label, return_tensors=\"pt\", max_length = 512, padding='max_length',truncation=True) #tokenized sentences\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31662f",
   "metadata": {
    "id": "9c31662f",
    "outputId": "e979fd34-64fa-4c9f-ae11-2a7ef46b2eee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_id=\"google/flan-t5-small\"\n",
    "saved_model = \"./Outputs/Trial-COT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(saved_model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46289722",
   "metadata": {
    "id": "46289722"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test-cot.csv')\n",
    "test_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da939769",
   "metadata": {
    "id": "da939769",
    "outputId": "7392a5f5-12de-4319-b830-1cb948167a39"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tokenized = test_data.map(collator, remove_columns=test_data.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd5bca",
   "metadata": {
    "id": "17bd5bca",
    "outputId": "f9bded01-c505-4b52-eada-b490ff7a24d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 160/160 [04:23<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataloader = DataLoader(test_data, batch_size=8)\n",
    "\n",
    "#perform inference\n",
    "predictions = []\n",
    "for data in tqdm(dataloader):\n",
    "\n",
    "    inputs = tokenizer(data['inputs'], return_tensors=\"pt\",max_length = 512, padding='max_length',truncation=True)\n",
    "    output_ids = model.generate(input_ids=inputs['input_ids'].cuda(), max_length = 512)\n",
    "    predictions.extend(tokenizer.batch_decode(output_ids,skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bca07",
   "metadata": {
    "id": "2f2bca07"
   },
   "outputs": [],
   "source": [
    "predicted_ans = [p.split(\" \")[-1] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566fde1",
   "metadata": {
    "id": "4566fde1"
   },
   "outputs": [],
   "source": [
    "count = [1 if p==t else 0 for p,t in zip(predicted_ans,test_data['ans'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33565aaf",
   "metadata": {
    "id": "33565aaf",
    "outputId": "ce7fa625-a607-4047-de9b-4b5b8362326a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131868131868132"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count)/len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ee2a4",
   "metadata": {
    "id": "249ee2a4"
   },
   "outputs": [],
   "source": [
    "# test_data = test_data.add_column(\"predictions\",predicted_ans)\n",
    "test_data = test_data.add_column(\"predictions_sent\",predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f9464",
   "metadata": {
    "id": "771f9464"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab1f69",
   "metadata": {
    "id": "a0ab1f69",
    "outputId": "167f2c1f-9687-4d7f-bd68-fac658812416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            ans_sent  \\\n",
      "0  The answer can be found in the sentence: 'Idah...   \n",
      "1  The answer can be found in the sentence: 'For ...   \n",
      "2  The actual answer can be found in the sentence...   \n",
      "3  The answer can be found in the sentence: 'We'v...   \n",
      "4  The actual answer can be found in the sentence...   \n",
      "\n",
      "                                    predictions_sent  \n",
      "0  The answer can be found in the sentence: 'Ital...  \n",
      "1  The answer can be found in the sentence: 'For ...  \n",
      "2  The actual answer can be found in the sentence...  \n",
      "3  The answer can be found in the sentence: 'We'v...  \n",
      "4  The actual answer can be found in the sentence...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['ans_sent','predictions_sent']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f4579",
   "metadata": {
    "id": "986f4579",
    "outputId": "3d6faf74-2e96-4e6d-a2cf-cab8f9f0311b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The actual answer can be found in the sentence: 'An ex-money processing manager for Brink's Company in Alabama who had access to bags and bags of quarters swapped out coins for beads and made off with nearly $200,000 in 2014, per the FBI.'. However, the answer is paraphrased  which is common for large numbers. The number: '200,000' is paraphrased to '200K' after dividing 200000 by 1000. So the answer is 200\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ans_sent','predictions_sent']].iloc[2]['ans_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135a2c1",
   "metadata": {
    "id": "8135a2c1",
    "outputId": "156bf91d-941b-45e2-e3d4-4b14b6dcec86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The actual answer can be found in the sentence: 'An ex-money processing manager for Brink's Company in Alabama who had access to bags and bags of quarters swapped out coins for beads and made off with nearly $200,000 in 2014, per the FBI.'. However, the answer is paraphrased which is common for large numbers. The number: '200,000' is paraphrased to '200K' after dividing 200000 by 1000. So the answer is 200\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ans_sent','predictions_sent']].iloc[2]['predictions_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5026a8",
   "metadata": {
    "id": "ff5026a8",
    "outputId": "01dd61c5-8f66-4ea6-ac4a-c1485af10ff6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178676/287675275.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  analysis['operation'] =  analysis['calculation'].apply(lambda x: x.split(\"(\")[0].strip())\n"
     ]
    }
   ],
   "source": [
    "analysis = df[['calculation','ans','predictions','ans_sent','predictions_sent']]\n",
    "analysis['operation'] =  analysis['calculation'].apply(lambda x: x.split(\"(\")[0].strip())\n",
    "missed = analysis[(analysis['ans']!=analysis['predictions'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be65d5",
   "metadata": {
    "id": "95be65d5",
    "outputId": "aad764eb-3fad-4a82-ab10-46858218369c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178676/1628603995.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missed['operation'] =  missed['calculation'].apply(lambda x: x.split(\"(\")[0].strip())\n"
     ]
    }
   ],
   "source": [
    " missed['operation'] =  missed['calculation'].apply(lambda x: x.split(\"(\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60557387",
   "metadata": {
    "id": "60557387",
    "outputId": "166af93c-0042-4111-8531-f2e97c5c8f9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Add           0.750000\n",
       "Copy          0.131336\n",
       "Divide        1.000000\n",
       "Multiply      1.000000\n",
       "Paraphrase    0.156250\n",
       "Round         0.820513\n",
       "SRound        1.000000\n",
       "Span          1.000000\n",
       "Subtract      0.958333\n",
       "Trans         0.129032\n",
       "Name: operation, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed['operation'].value_counts()/analysis['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06d2c6",
   "metadata": {
    "id": "6c06d2c6",
    "outputId": "0a4707ca-df87-404c-fb6c-6899f3d233b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Copy          868\n",
       "Trans         217\n",
       "Paraphrase     96\n",
       "Round          39\n",
       "Subtract       24\n",
       "Add            16\n",
       "Multiply        6\n",
       "Span            4\n",
       "Divide          3\n",
       "SRound          1\n",
       "Name: operation, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1885e",
   "metadata": {
    "id": "06f1885e",
    "outputId": "ecefa4e4-89f2-4999-eb2c-b588979b1917"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calculation</th>\n",
       "      <th>ans</th>\n",
       "      <th>predictions</th>\n",
       "      <th>ans_sent</th>\n",
       "      <th>predictions_sent</th>\n",
       "      <th>operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Subtract(109,9)</td>\n",
       "      <td>100</td>\n",
       "      <td>109</td>\n",
       "      <td>So the answer is 100</td>\n",
       "      <td>The answer can be found in the sentence: 'Mark...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Subtract(2014,2003)</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>The news published in the year 2014 and the ev...</td>\n",
       "      <td>The answer can be found in the sentence: 'Now,...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Subtract(93,3)</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>So the answer is 90</td>\n",
       "      <td>The answer can be found in the sentence: 'Rese...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Subtract(Trans(Six),Span(him))</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>So the answer is 5</td>\n",
       "      <td>The answer can be found in the sentence: 'Six ...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Subtract(2016,2000)</td>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>So the answer is 16</td>\n",
       "      <td>The answer can be found in the sentence: 'His ...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Subtract(2015,1985)</td>\n",
       "      <td>30</td>\n",
       "      <td>105</td>\n",
       "      <td>The news published in the year 2015 and the ev...</td>\n",
       "      <td>The news published in the year 2015 and the ev...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Subtract(2019,1969)</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>The news published in the year 2019 and the ev...</td>\n",
       "      <td>The news published in the year 2019 and the ev...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Subtract(2008,50)</td>\n",
       "      <td>1958</td>\n",
       "      <td>23</td>\n",
       "      <td>So the answer is 1958</td>\n",
       "      <td>The answer can be found in the sentence: 'Fans...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Subtract(23,Add(Span(Mother),Span(Baby)))</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>So the answer is 21</td>\n",
       "      <td>The answer can be found in the sentence: 'A su...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Subtract(4,2)</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>So the answer is 2</td>\n",
       "      <td>The answer can be found in the sentence: 'Befo...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Subtract(1991,1900)</td>\n",
       "      <td>91</td>\n",
       "      <td>1991</td>\n",
       "      <td>So the answer is 91</td>\n",
       "      <td>The answer can be found in the sentence: 'A fr...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Subtract(2010,1975)</td>\n",
       "      <td>35</td>\n",
       "      <td>75</td>\n",
       "      <td>The news published in the year 2010 and the ev...</td>\n",
       "      <td>The news published in the year 2010 and the ev...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Subtract(1961,1900)</td>\n",
       "      <td>61</td>\n",
       "      <td>1961</td>\n",
       "      <td>So the answer is 61</td>\n",
       "      <td>The answer can be found in the sentence: 'More...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Subtract(2017,1985)</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>The news published in the year 2017 and the ev...</td>\n",
       "      <td>The answer can be found in the sentence: 'Stev...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Subtract(2010,1600)</td>\n",
       "      <td>400</td>\n",
       "      <td>66</td>\n",
       "      <td>The news published in the year 2010 and the ev...</td>\n",
       "      <td>The news published in the year 2010 and the ev...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Subtract(1970,1900)</td>\n",
       "      <td>70</td>\n",
       "      <td>1970</td>\n",
       "      <td>So the answer is 70</td>\n",
       "      <td>The answer can be found in the sentence: 'Rath...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Subtract(2005,2000)</td>\n",
       "      <td>05</td>\n",
       "      <td>2005</td>\n",
       "      <td>So the answer is 05</td>\n",
       "      <td>The answer can be found in the sentence: 'USA ...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Subtract(2010,Span(last year))</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>So the answer is 2009</td>\n",
       "      <td>The answer can be found in the sentence: 'In a...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Subtract(1977,1)</td>\n",
       "      <td>1976</td>\n",
       "      <td>1977</td>\n",
       "      <td>So the answer is 1976</td>\n",
       "      <td>The answer can be found in the sentence: 'The ...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Subtract(4,1)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>So the answer is 3</td>\n",
       "      <td>The answer can be found in the sentence: 'A pr...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Subtract(2016,1961)</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>The news published in the year 2016 and the ev...</td>\n",
       "      <td>The news published in the year 2016 and the ev...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Subtract(2019,133)</td>\n",
       "      <td>1886</td>\n",
       "      <td>133</td>\n",
       "      <td>So the answer is 1886</td>\n",
       "      <td>The answer can be found in the sentence: 'Ahoy...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>Subtract(2006,2000)</td>\n",
       "      <td>06</td>\n",
       "      <td>2006</td>\n",
       "      <td>So the answer is 06</td>\n",
       "      <td>The answer can be found in the sentence: 'The ...</td>\n",
       "      <td>Subtract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    calculation   ans predictions  \\\n",
       "174                             Subtract(109,9)   100         109   \n",
       "183                         Subtract(2014,2003)    11           5   \n",
       "256                              Subtract(93,3)    90          93   \n",
       "273              Subtract(Trans(Six),Span(him))     5           6   \n",
       "293                         Subtract(2016,2000)    16        2016   \n",
       "294                         Subtract(2015,1985)    30         105   \n",
       "295                         Subtract(2019,1969)    50          66   \n",
       "338                           Subtract(2008,50)  1958          23   \n",
       "435   Subtract(23,Add(Span(Mother),Span(Baby)))    21          23   \n",
       "494                               Subtract(4,2)     2          13   \n",
       "502                         Subtract(1991,1900)    91        1991   \n",
       "523                         Subtract(2010,1975)    35          75   \n",
       "537                         Subtract(1961,1900)    61        1961   \n",
       "687                         Subtract(2017,1985)    32           7   \n",
       "732                         Subtract(2010,1600)   400          66   \n",
       "739                         Subtract(1970,1900)    70        1970   \n",
       "798                         Subtract(2005,2000)    05        2005   \n",
       "800              Subtract(2010,Span(last year))  2009        2010   \n",
       "814                            Subtract(1977,1)  1976        1977   \n",
       "1044                              Subtract(4,1)     3           2   \n",
       "1086                        Subtract(2016,1961)    56          66   \n",
       "1103                         Subtract(2019,133)  1886         133   \n",
       "1198                        Subtract(2006,2000)    06        2006   \n",
       "\n",
       "                                               ans_sent  \\\n",
       "174                                So the answer is 100   \n",
       "183   The news published in the year 2014 and the ev...   \n",
       "256                                 So the answer is 90   \n",
       "273                                  So the answer is 5   \n",
       "293                                 So the answer is 16   \n",
       "294   The news published in the year 2015 and the ev...   \n",
       "295   The news published in the year 2019 and the ev...   \n",
       "338                               So the answer is 1958   \n",
       "435                                 So the answer is 21   \n",
       "494                                  So the answer is 2   \n",
       "502                                 So the answer is 91   \n",
       "523   The news published in the year 2010 and the ev...   \n",
       "537                                 So the answer is 61   \n",
       "687   The news published in the year 2017 and the ev...   \n",
       "732   The news published in the year 2010 and the ev...   \n",
       "739                                 So the answer is 70   \n",
       "798                                 So the answer is 05   \n",
       "800                               So the answer is 2009   \n",
       "814                               So the answer is 1976   \n",
       "1044                                 So the answer is 3   \n",
       "1086  The news published in the year 2016 and the ev...   \n",
       "1103                              So the answer is 1886   \n",
       "1198                                So the answer is 06   \n",
       "\n",
       "                                       predictions_sent operation  \n",
       "174   The answer can be found in the sentence: 'Mark...  Subtract  \n",
       "183   The answer can be found in the sentence: 'Now,...  Subtract  \n",
       "256   The answer can be found in the sentence: 'Rese...  Subtract  \n",
       "273   The answer can be found in the sentence: 'Six ...  Subtract  \n",
       "293   The answer can be found in the sentence: 'His ...  Subtract  \n",
       "294   The news published in the year 2015 and the ev...  Subtract  \n",
       "295   The news published in the year 2019 and the ev...  Subtract  \n",
       "338   The answer can be found in the sentence: 'Fans...  Subtract  \n",
       "435   The answer can be found in the sentence: 'A su...  Subtract  \n",
       "494   The answer can be found in the sentence: 'Befo...  Subtract  \n",
       "502   The answer can be found in the sentence: 'A fr...  Subtract  \n",
       "523   The news published in the year 2010 and the ev...  Subtract  \n",
       "537   The answer can be found in the sentence: 'More...  Subtract  \n",
       "687   The answer can be found in the sentence: 'Stev...  Subtract  \n",
       "732   The news published in the year 2010 and the ev...  Subtract  \n",
       "739   The answer can be found in the sentence: 'Rath...  Subtract  \n",
       "798   The answer can be found in the sentence: 'USA ...  Subtract  \n",
       "800   The answer can be found in the sentence: 'In a...  Subtract  \n",
       "814   The answer can be found in the sentence: 'The ...  Subtract  \n",
       "1044  The answer can be found in the sentence: 'A pr...  Subtract  \n",
       "1086  The news published in the year 2016 and the ev...  Subtract  \n",
       "1103  The answer can be found in the sentence: 'Ahoy...  Subtract  \n",
       "1198  The answer can be found in the sentence: 'The ...  Subtract  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.to_csv('./Outputs/Trial-v2/predictions-v2.csv',index=False)\n",
    "missed[(missed.operation=='Subtract') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed441b",
   "metadata": {
    "id": "0aed441b"
   },
   "outputs": [],
   "source": [
    "subtract = missed[(missed.operation=='Subtract') & (missed['predictions_sent'].str.contains('The news published'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b52b9",
   "metadata": {
    "id": "c57b52b9",
    "outputId": "bd14007e-87e8-47d2-e942-17752ff080e5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The news published in the year 2010 and the event mentioned in the news happened in the year 1975, so the year mentioned in the headline comes from a subtraction of 2010-1975 = 35. so the answer is 35'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract.iloc[2]['ans_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2703bd",
   "metadata": {
    "id": "3c2703bd",
    "outputId": "b4c40983-6acb-4b08-eaf2-fef1839c8f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The news published in the year 2010 and the event mentioned in the news happened in the year 1975, so the year mentioned in the headline comes from a subtraction of 2010-1975 = 76. so the answer is 75'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract.iloc[2]['predictions_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd6891",
   "metadata": {
    "id": "67dd6891"
   },
   "outputs": [],
   "source": [
    "Add           0.625000\n",
    "Copy          0.104839\n",
    "Divide        1.000000\n",
    "Multiply      1.000000\n",
    "Paraphrase    0.214286\n",
    "Round         0.794872\n",
    "SRound        1.000000\n",
    "Span          0.750000\n",
    "Subtract      0.821429\n",
    "Trans         0.103139"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
