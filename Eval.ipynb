{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15709730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 22:10:45.123664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, MT5ForConditionalGeneration, MT5Tokenizer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer\n",
    "os.environ['WANDB_SILENT']=\"true\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f355e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "def file_loader(json_path):\n",
    "    with open(json_path) as f:\n",
    "        contents = f.read()\n",
    "    return json.loads(contents)\n",
    "\n",
    "numerical_reasoning_test = \"Test_Numerical_Reasoning.json\"\n",
    "\n",
    "\n",
    "numerical_data_test_path = os.path.join(\"Dataset\", numerical_reasoning_test)\n",
    "\n",
    "numerical_data_test = file_loader(numerical_data_test_path)\n",
    "df_test = pd.DataFrame.from_dict(numerical_data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ef0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f725fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['context'] = df_test['news'].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x, 1).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a131a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(item):\n",
    "\n",
    "    headline = item[\"masked headline\"]\n",
    "    return f\"{item['news']}\\n\\n Fill in the blank: {headline}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab66eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['t5-input'] = df_test.apply(lambda x: process_input(x),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646eadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca17243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.save_to_disk('./Dataset/test-final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fa6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "\n",
    "    input = batch['t5-input'] #load original sentences\n",
    "#     label = batch['ans'] #load noisy sentences\n",
    "    inputs = tokenizer(input, return_tensors=\"pt\", max_length = 512, padding='max_length',truncation=True) #tokenized sentences\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9596e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_id=\"google/flan-t5-small\"\n",
    "saved_model = \"./Outputs/Trial-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(saved_model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a812facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4921 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tokenized = test.map(collator, remove_columns=test.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed438bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 616/616 [01:35<00:00,  6.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataloader = DataLoader(test, batch_size=8)\n",
    "\n",
    "#perform inference\n",
    "predictions = []\n",
    "for data in tqdm(dataloader):\n",
    "\n",
    "    inputs = tokenizer(data['t5-input'], return_tensors=\"pt\",max_length = 512, padding='max_length',truncation=True)\n",
    "    output_ids = model.generate(input_ids=inputs['input_ids'].cuda(), max_length = 512)\n",
    "    predictions.extend(tokenizer.batch_decode(output_ids,skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bfcdc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c0dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['ID'] = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba72546",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['Pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62fa4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('Small-preds.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0ff847e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>masked headline</th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>t5-input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Dec 21, 2011  5:52 PM) A burglar made a huge ...</td>\n",
       "      <td>IT Guy Foils Burglar From ____ Blocks Away</td>\n",
       "      <td>0</td>\n",
       "      <td>A burglar made a huge mistake yesterday when h...</td>\n",
       "      <td>(Dec 21, 2011  5:52 PM) A burglar made a huge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Dec 22, 2013  3:00 PM) You probably felt pret...</td>\n",
       "      <td>8 Stars Who Hit ____ This Year</td>\n",
       "      <td>1</td>\n",
       "      <td>You probably felt pretty old when you learned ...</td>\n",
       "      <td>(Dec 22, 2013  3:00 PM) You probably felt pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Apr 23, 2014  4:53 AM CDT) In a case most com...</td>\n",
       "      <td>3 Text Messages to Fan Cost Buffalo Bills $____M</td>\n",
       "      <td>2</td>\n",
       "      <td>In a case most commentators are calling frivol...</td>\n",
       "      <td>(Apr 23, 2014  4:53 AM CDT) In a case most com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(May 10, 2016  5:57 AM CDT) Ryan Gosling and E...</td>\n",
       "      <td>Gosling, Mendes Had Secret Baby No. ____</td>\n",
       "      <td>3</td>\n",
       "      <td>Ryan Gosling and Eva Mendes have pulled off wh...</td>\n",
       "      <td>(May 10, 2016  5:57 AM CDT) Ryan Gosling and E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Jan 11, 2010  7:41 AM) Gay marriage will have...</td>\n",
       "      <td>Landmark Prop ____ Trial to Begin Today</td>\n",
       "      <td>4</td>\n",
       "      <td>Gay marriage will have its day in federal cour...</td>\n",
       "      <td>(Jan 11, 2010  7:41 AM) Gay marriage will have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>(Sep 9, 2012  9:55 AM CDT) If you're looking f...</td>\n",
       "      <td>London's 'WeirWolf' Wins ____th Gold</td>\n",
       "      <td>4995</td>\n",
       "      <td>If you're looking for the star of London's Par...</td>\n",
       "      <td>(Sep 9, 2012  9:55 AM CDT) If you're looking f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>(Apr 22, 2010  1:21 PM CDT) The Coast Guard is...</td>\n",
       "      <td>La. Oil Rig Sinks; ____ Still Missing</td>\n",
       "      <td>4996</td>\n",
       "      <td>The Coast Guard is saying that an oil platform...</td>\n",
       "      <td>(Apr 22, 2010  1:21 PM CDT) The Coast Guard is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>(Aug 27, 2012  12:03 AM CDT) Some 300 earthqua...</td>\n",
       "      <td>____-Quake 'Storm' Rattles California</td>\n",
       "      <td>4997</td>\n",
       "      <td>Some 300 earthquakes shook up Southern Califor...</td>\n",
       "      <td>(Aug 27, 2012  12:03 AM CDT) Some 300 earthqua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>(Dec 8, 2008  5:40 PM) Under a wave of critici...</td>\n",
       "      <td>Merrill CEO Backs Off $____M Bonus Request</td>\n",
       "      <td>4998</td>\n",
       "      <td>Under a wave of criticism, Merrill Lynch CEO J...</td>\n",
       "      <td>(Dec 8, 2008  5:40 PM) Under a wave of critici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>(Jan 25, 2016  3:19 PM) US stocks are closing ...</td>\n",
       "      <td>Stocks Slip, Oil Skids ____%</td>\n",
       "      <td>4999</td>\n",
       "      <td>US stocks are closing lower as the beleaguered...</td>\n",
       "      <td>(Jan 25, 2016  3:19 PM) US stocks are closing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4921 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   news  \\\n",
       "0     (Dec 21, 2011  5:52 PM) A burglar made a huge ...   \n",
       "1     (Dec 22, 2013  3:00 PM) You probably felt pret...   \n",
       "2     (Apr 23, 2014  4:53 AM CDT) In a case most com...   \n",
       "3     (May 10, 2016  5:57 AM CDT) Ryan Gosling and E...   \n",
       "4     (Jan 11, 2010  7:41 AM) Gay marriage will have...   \n",
       "...                                                 ...   \n",
       "4916  (Sep 9, 2012  9:55 AM CDT) If you're looking f...   \n",
       "4917  (Apr 22, 2010  1:21 PM CDT) The Coast Guard is...   \n",
       "4918  (Aug 27, 2012  12:03 AM CDT) Some 300 earthqua...   \n",
       "4919  (Dec 8, 2008  5:40 PM) Under a wave of critici...   \n",
       "4920  (Jan 25, 2016  3:19 PM) US stocks are closing ...   \n",
       "\n",
       "                                       masked headline    id  \\\n",
       "0           IT Guy Foils Burglar From ____ Blocks Away     0   \n",
       "1                       8 Stars Who Hit ____ This Year     1   \n",
       "2     3 Text Messages to Fan Cost Buffalo Bills $____M     2   \n",
       "3             Gosling, Mendes Had Secret Baby No. ____     3   \n",
       "4              Landmark Prop ____ Trial to Begin Today     4   \n",
       "...                                                ...   ...   \n",
       "4916              London's 'WeirWolf' Wins ____th Gold  4995   \n",
       "4917             La. Oil Rig Sinks; ____ Still Missing  4996   \n",
       "4918             ____-Quake 'Storm' Rattles California  4997   \n",
       "4919        Merrill CEO Backs Off $____M Bonus Request  4998   \n",
       "4920                      Stocks Slip, Oil Skids ____%  4999   \n",
       "\n",
       "                                                context  \\\n",
       "0     A burglar made a huge mistake yesterday when h...   \n",
       "1     You probably felt pretty old when you learned ...   \n",
       "2     In a case most commentators are calling frivol...   \n",
       "3     Ryan Gosling and Eva Mendes have pulled off wh...   \n",
       "4     Gay marriage will have its day in federal cour...   \n",
       "...                                                 ...   \n",
       "4916  If you're looking for the star of London's Par...   \n",
       "4917  The Coast Guard is saying that an oil platform...   \n",
       "4918  Some 300 earthquakes shook up Southern Califor...   \n",
       "4919  Under a wave of criticism, Merrill Lynch CEO J...   \n",
       "4920  US stocks are closing lower as the beleaguered...   \n",
       "\n",
       "                                               t5-input  \n",
       "0     (Dec 21, 2011  5:52 PM) A burglar made a huge ...  \n",
       "1     (Dec 22, 2013  3:00 PM) You probably felt pret...  \n",
       "2     (Apr 23, 2014  4:53 AM CDT) In a case most com...  \n",
       "3     (May 10, 2016  5:57 AM CDT) Ryan Gosling and E...  \n",
       "4     (Jan 11, 2010  7:41 AM) Gay marriage will have...  \n",
       "...                                                 ...  \n",
       "4916  (Sep 9, 2012  9:55 AM CDT) If you're looking f...  \n",
       "4917  (Apr 22, 2010  1:21 PM CDT) The Coast Guard is...  \n",
       "4918  (Aug 27, 2012  12:03 AM CDT) Some 300 earthqua...  \n",
       "4919  (Dec 8, 2008  5:40 PM) Under a wave of critici...  \n",
       "4920  (Jan 25, 2016  3:19 PM) US stocks are closing ...  \n",
       "\n",
       "[4921 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f93cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(Apr 23, 2014  4:53 AM CDT) In a case most commentators are calling frivolous, finicky, or just plain silly, the Buffalo Bills have coughed up $3 million to settle a lawsuit from a fan who complained that the team sent him too many text messages. The fan brought the class-action suit after he signed up for the team's news service, which promised three to five texts a week, but then received six messages one week and seven the next, reports the Buffalo News. The fan claimed that the extra messages violated the Federal Telephone Consumer Protection Act and sought damages of around $2,000 per message. Under the terms of the settlement, the tens of thousands of fans who signed up for the now-defunct service will receive a total of around $2.5 million in the form of debit cards redeemable only at the team's store, the New York Post reports. The fan's lawyers will receive more than $500,000 under the settlement and he will get $5,000.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[2]['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8238e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
